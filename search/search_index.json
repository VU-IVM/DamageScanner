{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DamageScanner: direct damage assessments for natural hazards","text":"<p>A python toolkit for direct damage assessments for natural hazards. Even though the method is initially developed for flood damage assessments, it can calculate damages for any hazard for which you just require a vulnerability curve (i.e. a one-dimensional relation). </p> <p>Please note: This package is still in development phase. In case of any problems, or if you have any suggestions for improvements, please raise an issue. </p>"},{"location":"#background","title":"Background","text":"<p>This package is (loosely) based on the original DamageScanner, which calculated potential flood damages based on inundation depth and land use using depth-damage curves in the Netherlands. The DamageScanner was originally developed for the 'Netherlands Later' project (Klijn et al., 2007). The original land-use classes were based on the Land-Use Scanner in order to evaluate the effect of future land-use change on flood damages. </p>"},{"location":"#installation","title":"Installation","text":"<ol> <li>Open the python environment in your command prompt or bash in which you want to install this package.</li> <li>Type <code>pip install damagescanner</code> and it should install itself into your python environment.</li> <li>Now you can import the package like any other package!</li> </ol>"},{"location":"#how-to-cite","title":"How to cite","text":"<p>If you use the DamageScanner in your work, please cite the package directly:</p> <ul> <li>Koks. E.E. (2022). DamageScanner: Python tool for natural hazard damage assessments. Zenodo. http://doi.org/10.5281/zenodo.2551015</li> </ul>"},{"location":"#license","title":"License","text":"<p>Copyright (C) 2025 Elco Koks &amp; Jens de Bruijn. All versions released under the MIT license.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#core-module","title":"Core Module","text":""},{"location":"api/#damagescanner.core.DamageScanner.exposure","title":"<code>exposure(disable_progress=False, **kwargs)</code>","text":"<p>Exposure data</p> Source code in <code>damagescanner\\core.py</code> <pre><code>def exposure(self, disable_progress=False, **kwargs):\n    \"\"\"Exposure data\"\"\"\n\n    if self.assessment_type == \"raster\":\n        return xr.open_rasterio(self.exposure_data)\n\n    elif self.assessment_type == \"vector\":\n        # specificy essential data input characteristics\n        if \"asset_type\" in kwargs:\n            self.asset_type = kwargs.get(\"asset_type\")\n        else:\n            self.asset_type = \"landuse\"\n\n        exposed_assets = VectorExposure(\n            hazard_file=self.hazard_data,\n            feature_file=self.feature_data,\n            asset_type=self.asset_type,\n            disable_progress=disable_progress,\n        )[0]\n\n        return exposed_assets\n</code></pre>"},{"location":"api/#damagescanner.core.DamageScanner.calculate","title":"<code>calculate(disable_progress=False, save_output=False, **kwargs)</code>","text":"<p>Damage assessment. Can be a specific hazard event, or a specific             single hazard footprint, or a list of events/footprints.</p> Source code in <code>damagescanner\\core.py</code> <pre><code>def calculate(self, disable_progress=False, save_output=False, **kwargs):\n    \"\"\"Damage assessment. Can be a specific hazard event, or a specific \\\n        single hazard footprint, or a list of events/footprints.\"\"\"\n\n    if not hasattr(self, \"assessment_type\"):\n        raise ImportError(\"Please prepare the input data first\")\n\n    if self.assessment_type == \"raster\":\n        return RasterScanner(\n            exposure_file=self.feature_data,\n            hazard_file=self.hazard_data,\n            curve_path=self.curves,\n            maxdam_path=self.maxdam,\n            save=save_output,\n        )\n\n    elif self.assessment_type == \"vector\":\n        # specificy essential data input characteristics\n        if \"asset_type\" in kwargs:\n            self.asset_type = kwargs.get(\"asset_type\")\n        else:\n            self.asset_type = None\n\n        return VectorScanner(\n            hazard_file=self.hazard_data,\n            feature_file=self.feature_data,\n            curve_path=self.curves,\n            maxdam_path=self.maxdam,\n            asset_type=self.asset_type,  #'landuse',\n            multi_curves=kwargs.get(\"multi_curves\", None),\n            sub_types=kwargs.get(\"subtypes\", None),\n            disable_progress=disable_progress,\n            save=save_output,\n        )\n</code></pre>"},{"location":"api/#damagescanner.core.DamageScanner.risk","title":"<code>risk(hazard_dict, **kwargs)</code>","text":"<p>Calculate the risk for a list of hazard events</p> Source code in <code>damagescanner\\core.py</code> <pre><code>def risk(self, hazard_dict, **kwargs):\n    \"\"\"\n    Calculate the risk for a list of hazard events\n    \"\"\"\n\n    RP_list = list(hazard_dict.keys())\n\n    risk = {}\n    for key, hazard_map in tqdm(\n        hazard_dict.items(), total=len(hazard_dict), desc=\"Risk Calculation\"\n    ):\n        if self.assessment_type == \"raster\":\n            risk[key] = DamageScanner(\n                hazard_map, self.feature_data, self.curves, self.maxdam\n            ).calculate(disable_progress=True)[0]\n        else:\n            if kwargs.get(\"asset_type\", None) is not None:\n                risk[key] = DamageScanner(\n                    hazard_map, self.feature_data, self.curves, self.maxdam\n                ).calculate(\n                    disable_progress=True, asset_type=kwargs.get(\"asset_type\")\n                )\n            elif kwargs.get(\"multi_curves\", None) is not None:\n                risk[key] = DamageScanner(\n                    hazard_map, self.feature_data, self.curves, self.maxdam\n                ).calculate(\n                    disable_progress=True, multi_curves=kwargs.get(\"multi_curves\")\n                )\n            else:\n                risk[key] = DamageScanner(\n                    hazard_map, self.feature_data, self.curves, self.maxdam\n                ).calculate(disable_progress=True)\n\n    # Collect the risk for each RP\n    df_risk = pd.concat(risk, axis=1)\n\n    if (len(df_risk) == 0) or (df_risk.isnull().all().all()):\n        return None\n\n    # Get the dataframe of the largest RP\n    largest_rp = df_risk.loc[:, pd.IndexSlice[RP_list[-1], :]]\n\n    if kwargs.get(\"multi_curves\", None) is None:\n        # only keep the damage values\n        df_risk = df_risk.loc[:, pd.IndexSlice[RP_list, \"damage\"]].fillna(0)\n\n        RPS = [1 / x for x in RP_list]\n\n        risk = pd.DataFrame(\n            df_risk.apply(\n                lambda x: integrate.simpson(y=x[RP_list][::-1], x=RPS[::-1]), axis=1\n            ),\n            columns=[\"tot_risk\"],\n        )\n\n        # save output when tot_risk returns negative values\n        if risk.tot_risk.min() &lt; 0:\n            df_risk.to_csv(\"df_risk.csv\")\n            risk.to_csv(\"risk.csv\")\n\n        # Save the risk to the largest RP\n        largest_rp.columns = largest_rp.columns.get_level_values(1)\n        largest_rp = largest_rp.drop(\"damage\", axis=1)\n        largest_rp.loc[:, \"risk\"] = risk.values\n\n        # return the risk in a concise dataframe\n        return largest_rp[[\"osm_id\", \"object_type\", \"geometry\", \"risk\"]]\n\n    else:\n        multi_curves = kwargs.get(\"multi_curves\")\n\n        # only keep the damage values\n        df_risk = df_risk.loc[\n            :, pd.IndexSlice[RP_list, multi_curves.keys()]\n        ].fillna(0)\n\n        RPS = [1 / x for x in RP_list]\n\n        # estimate risks\n        collect_risks = {}\n\n        for curve in multi_curves.keys():\n            subrisk = df_risk.loc[:, pd.IndexSlice[:, curve]]\n            collect_risks[curve] = subrisk.apply(\n                lambda x: integrate.simpson(y=x[RP_list][::-1], x=RPS[::-1]), axis=1\n            ).values\n\n            # save output when tot_risk returns negative values\n            if any(subrisk.min() &lt; 0):\n                df_risk.to_csv(\"df_risk.csv\")\n                subrisk.to_csv(\"risk.csv\")\n\n        all_risks = pd.DataFrame.from_dict(collect_risks)\n\n        largest_rp.columns = largest_rp.columns.get_level_values(1)\n        largest_rp = largest_rp.drop(multi_curves.keys(), axis=1)\n        largest_rp.loc[:, multi_curves.keys()] = all_risks.values\n\n        # return the risk in a concise dataframe\n        return largest_rp[\n            [\"osm_id\", \"object_type\", \"geometry\"] + list(multi_curves.keys())\n        ]\n</code></pre>"},{"location":"api/#vector-based-specific-functions","title":"Vector-based Specific Functions","text":""},{"location":"api/#damagescanner.vector.VectorExposure","title":"<code>VectorExposure(hazard_file, feature_file, asset_type='roads', object_col='object_type', disable_progress=False)</code>","text":"<p>Function to assess the exposure of objects.</p> <p>Parameters:</p> Name Type Description Default <code>hazard_file</code> <code>str</code> <p>Path to the hazard file.</p> required <code>exposure_file</code> <code>str</code> <p>Path to the exposure file.</p> required <p>Returns:</p> Type Description <p>gpd.GeoDataFrame: GeoDataFrame with the hazard and exposure information.</p> Source code in <code>damagescanner\\vector.py</code> <pre><code>def VectorExposure(hazard_file, feature_file, asset_type=\"roads\",object_col=\"object_type\", disable_progress=False):\n    \"\"\"\n    Function to assess the exposure of objects.\n\n    Args:\n        hazard_file (str): Path to the hazard file.\n        exposure_file (str): Path to the exposure file.\n\n    Returns:\n        gpd.GeoDataFrame: GeoDataFrame with the hazard and exposure information.\n    \"\"\"\n    # load exposure data\n    if isinstance(feature_file, PurePath):\n        # if exposure_file is a shapefile, geopackage or parquet file\n        if feature_file.suffix in [\".shp\", \".gpkg\", \"parquet\"]:\n            features = gpd.read_file(feature_file)\n\n        # if exposure_file is an osm.pbf file\n        elif feature_file.suffix == \".pbf\":\n            features = read_osm_data(feature_file, asset_type)\n            object_col = \"object_type\"\n        else:\n            raise ValueError(\n                \"exposure data should either be a shapefile, geopackage, parquet or osm.pbf file\"\n            )\n\n    elif isinstance(feature_file, gpd.GeoDataFrame) | isinstance(\n        feature_file, pd.DataFrame\n    ):\n        features = gpd.GeoDataFrame(feature_file.copy())\n\n    else:\n        raise ValueError(\n            \"exposure data should either be a shapefile, geopackage, parquet or osm.pbf file\"\n        )\n\n    if len(features) == 0:\n        hazard_crs = None\n        cell_area_m2 = None\n        return features, object_col, hazard_crs , cell_area_m2\n\n    # load hazard data\n    if isinstance(hazard_file, PurePath):\n        if hazard_file.suffix in [\".tif\", \".tiff\", \".nc\"]:\n            hazard = xr.open_dataset(hazard_file, engine=\"rasterio\")\n            hazard_crs = hazard.rio.crs\n\n            # check if crs is already in meters\n            if pyproj.CRS.from_epsg(hazard_crs.to_epsg()).axis_info[0].unit_name == \"metre\":\n                cell_area_m2 = (hazard.x[1].values - hazard.x[0].values) * (hazard.y[0].values - hazard.y[1].values)\n            else:\n                cell_area_m2 = _get_cell_area_m2(features,abs(hazard.rio.resolution()[0]))\n\n        elif hazard_file.suffix in [\".shp\", \".gpkg\", \".pbf\"]:\n            hazard = gpd.read_file(hazard_file)\n            hazard_crs = hazard.crs\n            cell_area_m2 = 1\n        else:\n            raise ValueError(\n                \"hazard data should either be a geotiff, netcdf, shapefile, geopackage or parquet file\"\n            )\n    elif isinstance(hazard_file, rasterio.io.DatasetReader):\n        hazard = hazard_file.copy()\n        hazard_crs = hazard.crs\n        cell_area_m2 = _get_cell_area_m2(features,abs(hazard.res[0]))\n    elif isinstance(hazard_file, (xr.Dataset, xr.DataArray)):   \n        hazard = hazard_file.copy()\n        hazard_crs = hazard.rio.crs\n\n        # check if crs is already in meters\n        if pyproj.CRS.from_epsg(hazard_crs.to_epsg()).axis_info[0].unit_name == \"metre\":\n            cell_area_m2 = (hazard.x[1].values - hazard.x[0].values) * (hazard.y[0].values - hazard.y[1].values)\n\n        # if not, extract it more cumbersome\n        else:\n            cell_area_m2 = _get_cell_area_m2(features,abs(hazard.rio.resolution()[0]))\n\n    elif isinstance(hazard, gpd.GeoDataFrame):\n        hazard = hazard_file.copy()\n        hazard_crs = hazard.crs\n        cell_area_m2 = 1\n    else:\n        raise ValueError(\n            f\"Hazard should be a raster or GeoDataFrame object, {type(hazard)} given\"\n        )\n\n    # Run exposure overlay\n    if isinstance(hazard, (rasterio.io.DatasetReader, xr.Dataset, xr.DataArray)):\n        features = _overlay_raster_vector(hazard, features, hazard_crs, disable_progress=disable_progress)\n    elif isinstance(hazard, (gpd.GeoDataFrame, pd.DataFrame)): \n        features = _overlay_vector_vector(hazard, features) ## NOT WORKING YET\n\n    return features, object_col, hazard_crs, cell_area_m2\n</code></pre>"},{"location":"api/#damagescanner.vector.VectorScanner","title":"<code>VectorScanner(hazard_file, feature_file, curve_path, maxdam_path, asset_type='roads', multi_curves=dict(), object_col='object_type', disable_progress=False, save=False, **kwargs)</code>","text":"<p>Vector based implementation of a direct damage assessment</p> <p>Parameters:</p> Name Type Description Default <code>*exposure_file*</code> <p>Shapefile, Pandas DataFrame or Geopandas GeoDataFrame</p> required <code>*hazard_file*</code> <p>GeoTiff with inundation depth per grid cell. Make sure</p> required <code>*curve_path*</code> <p>File with the stage-damage curves of the different</p> required <code>*maxdam_path*</code> <p>File with the maximum damages per land-use class</p> required <p>Optional Arguments:</p> <pre><code>*object_col* : Specify the column name of the unique object id's.\nDefault is set to **landuse**.\n\n*sub_types* : List of subtypes that should be included in the analysis.\n\n*save* : Set to True if you would like to save the output. Requires\nseveral **kwargs**\n</code></pre> kwargs <p>output_path : Specify where files should be saved.</p> <p>scenario_name: Give a unique name for the files that are going to be saved.</p> <p>Raises:</p> Type Description <code>*ValueError* </code> <p>on missing kwargs</p> <p>Returns:</p> Type Description <p>damagebin : Table with the land-use class names (1st column) and the</p> <p>damage for that land-use class (2nd column).</p> <p>TO DO: add the option to use vector data for the hazard as well.</p> Source code in <code>damagescanner\\vector.py</code> <pre><code>def VectorScanner(\n    hazard_file,\n    feature_file,\n    curve_path,\n    maxdam_path,\n    asset_type=\"roads\",\n    multi_curves=dict(),\n    object_col=\"object_type\",\n    disable_progress=False,\n    save=False,\n    **kwargs,\n):\n    \"\"\"\n    Vector based implementation of a direct damage assessment\n\n    Arguments:\n        *exposure_file* : Shapefile, Pandas DataFrame or Geopandas GeoDataFrame\n        with land-use information of the area.\n\n        *hazard_file* : GeoTiff with inundation depth per grid cell. Make sure\n        that the unit of the inundation map corresponds with the unit of the\n        first column of the curves file.\n\n        *curve_path* : File with the stage-damage curves of the different\n        land-use classes. Can also be a pandas DataFrame (but not a numpy Array).\n\n        *maxdam_path* : File with the maximum damages per land-use class\n        (in euro/m2). Can also be a pandas DataFrame (but not a numpy Array).\n\n    Optional Arguments:\n\n        *object_col* : Specify the column name of the unique object id's.\n        Default is set to **landuse**.\n\n        *sub_types* : List of subtypes that should be included in the analysis.\n\n        *save* : Set to True if you would like to save the output. Requires\n        several **kwargs**\n\n    kwargs:\n        *output_path* : Specify where files should be saved.\n\n        *scenario_name*: Give a unique name for the files that are going to be saved.\n\n    Raises:\n        *ValueError* : on missing kwargs\n\n    Returns:\n     *damagebin* : Table with the land-use class names (1st column) and the\n     damage for that land-use class (2nd column).\n\n    TO DO: add the option to use vector data for the hazard as well.\n\n    \"\"\"\n\n    # Load hazard and exposure data, and perform the overlay\n    features, object_col, hazard_crs, cell_area_m2 = VectorExposure(\n        hazard_file, feature_file, asset_type, object_col, disable_progress\n    )\n\n    if len(features) == 0:\n        return features\n\n    # Load curves\n    if isinstance(curve_path, pd.DataFrame):\n        curves = curve_path.copy()\n    elif isinstance(curve_path, np.ndarray):\n        raise ValueError(\n            \"For the vector-based approach we use a pandas DataFrame, not a Numpy Array\"\n        )\n    elif curve_path.parts[-1].endswith(\".csv\"):\n        curves = pd.read_csv(curve_path, index_col=[0])\n\n    # Load maximum damages\n    if isinstance(maxdam_path, PurePath) and maxdam_path.parts[-1].endswith(\".csv\"):\n        maxdam = pd.read_csv(maxdam_path)\n        maxdam = dict(zip(maxdam[\"object_type\"], maxdam[\"damage\"]))\n    elif isinstance(maxdam_path, pd.DataFrame):\n        maxdam = dict(zip(maxdam_path[\"object_type\"], maxdam_path[\"damage\"]))\n    elif isinstance(maxdam_path, np.ndarray):\n        maxdam = dict(zip(maxdam_path[:, 0], maxdam_path[:, 1]))\n    elif isinstance(maxdam_path, dict):\n        maxdam = maxdam_path\n\n    # remove features that are not part of this object type\n    if asset_type in DICT_CIS_VULNERABILITY_FLOOD.keys():\n        unique_objects_in_asset_type = list(DICT_CIS_VULNERABILITY_FLOOD[asset_type].keys())\n        features = features[features['object_type'].isin(unique_objects_in_asset_type)]\n\n    # connect maxdam to exposure\n    try:\n        features[\"maximum_damage\"] = features.apply(\n            lambda x: maxdam[x[\"object_type\"]], axis=1\n        )\n    except KeyError:\n        missing_object_types = [i for i in features.object_type.unique() if i not in maxdam.keys()]\n        raise KeyError(\n           f\"Not all object types in the exposure are included in the maximum damage file: {missing_object_types}\"\n        )\n\n    tqdm.pandas(desc=\"Calculating damage\",disable=disable_progress)\n\n    # Calculate damage\n    if not multi_curves:\n        features = _estimate_damage(features, curves, cell_area_m2)\n    else:\n        collect_sub_outcomes  = []\n        for curve_id in multi_curves:\n            curves = multi_curves[curve_id]\n            collect_sub_outcomes.append(_estimate_damage(features, curves, cell_area_m2)['damage'])\n\n        all_curve_damages = pd.concat(collect_sub_outcomes,axis=1)\n        all_curve_damages.columns = multi_curves.keys()\n\n        # add all curve damages to the features dataframe\n        features.loc[:,all_curve_damages.columns] = all_curve_damages\n\n        if 'damage' in features.columns:\n            features = features.drop(columns='damage')\n\n    # # Save output\n    # if save == True:\n    #     # requires adding output_path and scenario_name to function call\n    #     # If output path is not defined, will place file in current directory\n    #     output_path = _check_output_path(kwargs)\n    #     scenario_name = _check_scenario_name(kwargs)\n    #     path_prefix = PurePath(output_path, scenario_name)\n\n    #     damage_fn = f'{path_prefix}_damages.csv'\n    #     damaged_objects.to_csv(damage_fn)\n    #     return damaged_objects\n\n    # else:\n    #     return damaged_objects\n\n    return features\n</code></pre>"},{"location":"api/#raster-based-specific-functions","title":"Raster-based Specific Functions","text":""},{"location":"api/#damagescanner.raster.match_and_load_rasters","title":"<code>match_and_load_rasters(raster_in1, raster_in2)</code>","text":"<p>In case of a mismatch between two rasters, return only the intersecting parts.</p> <p>Code adapted from http://sciience.tumblr.com/post/101722591382/finding-the-georeferenced-intersection-between-two</p> <p>Parameters:</p> Name Type Description Default <code>*raster_in1*</code> <p>One of the two rasters to be clipped to the overlapping extent.</p> required <code>*raster_in2*</code> <p>One of the two rasters to be clipped to the overlapping extent.</p> required <p>Returns:</p> Type Description <p>array1 : Numpy Array of raster1</p> <p>array2 : Numpy Array of raster2</p> <p>intersection : Bounding box of overlapping part</p> Source code in <code>damagescanner\\raster.py</code> <pre><code>def match_and_load_rasters(raster_in1, raster_in2):\n    \"\"\"\n    In case of a mismatch between two rasters, return only the intersecting parts.\n\n    Code adapted from http://sciience.tumblr.com/post/101722591382/finding-the-georeferenced-intersection-between-two\n\n    Arguments:\n        *raster_in1* : One of the two rasters to be clipped to the overlapping extent.\n\n        *raster_in2* : One of the two rasters to be clipped to the overlapping extent.\n\n    Returns:\n        *array1* : Numpy Array of raster1\n\n        *array2* : Numpy Array of raster2\n\n        *intersection* : Bounding box of overlapping part\n\n    \"\"\"\n    with rasterio.open(raster_in1) as src1, rasterio.open(raster_in2) as src2:\n        if src1.crs != src2.crs:\n            raise ValueError(\"Different CRS: CRS must be the same.\")\n        if src1.res != src2.res:\n            raise ValueError(\"Different resolution: Cell sizes must be the same.\")\n\n        top_delta = round((src2.bounds.top - src1.bounds.top) / src1.transform.e)\n        bottom_delta = round(\n            (src2.bounds.bottom - src1.bounds.bottom) / src1.transform.e\n        )\n        left_delta = round((src2.bounds.left - src1.bounds.left) / src1.transform.a)\n        right_delta = round((src2.bounds.right - src1.bounds.right) / src1.transform.a)\n\n        data1 = src1.read(\n            1,\n            window=Window(\n                col_off=left_delta,\n                row_off=top_delta,\n                width=src1.width - left_delta + right_delta,\n                height=src1.height - top_delta + bottom_delta,\n            ),\n        )\n        data2 = src2.read(\n            1,\n            window=Window(\n                col_off=abs(min(left_delta, 0)),\n                row_off=abs(min(top_delta, 0)),\n                width=max(src1.width, src2.width) - abs(left_delta) - abs(right_delta),\n                height=max(src1.height, src2.height)\n                - abs(top_delta)\n                - abs(bottom_delta),\n            ),\n        )\n        transform = rasterio.Affine(\n            src1.transform.a,\n            src1.transform.b,\n            src1.transform.c + src1.transform.a * max(left_delta, 0),\n            src1.transform.d,\n            src1.transform.e,\n            src1.transform.f + src1.transform.e * max(top_delta, 0),\n        )\n\n    return data1, data2, transform\n</code></pre>"},{"location":"api/#damagescanner.raster.RasterScanner","title":"<code>RasterScanner(exposure_file, hazard_file, curve_path, maxdam_path, lu_crs=28992, haz_crs=4326, hazard_col='FX', dtype=np.int32, save=False, **kwargs)</code>","text":"<p>Raster-based implementation of a direct damage assessment.</p> <p>Parameters:</p> Name Type Description Default <code>*landuse_file*</code> <p>GeoTiff with land-use information per grid cell. Make sure</p> required <code>*hazard_file*</code> <p>GeoTiff or netCDF4 with hazard intensity per grid cell. Make sure</p> required <code>*curve_path*</code> <p>File with the stage-damage curves of the different</p> required <code>*maxdam_path*</code> <p>File with the maximum damages per land-use class</p> required <code>*dtype*</code> <p>Set the dtype to the requires precision. This will affect the output damage raster as well</p> required Optional Arguments <p>save : Set to True if you would like to save the output. Requires several kwargs</p> kwargs <p>nan_value : if nan_value is provided, will mask the inundation file. This option can significantly fasten computations</p> <p>cell_size : If both the landuse and hazard map are numpy arrays, manually set the cell size.</p> <p>resolution : If landuse is a numpy array, but the hazard map is a netcdf, you need to specify the resolution of the landuse map.</p> <p>output_path : Specify where files should be saved.</p> <p>scenario_name: Give a unique name for the files that are going to be saved.</p> <p>in_millions: Set to True if all values should be set in millions.</p> <p>crs: Specify crs if you only read in two numpy array</p> <p>transform: Specify transform if you only read in numpy arrays in order to save the result raster</p> <p>Raises:</p> Type Description <code>*ValueError* </code> <p>on missing kwarg options</p> <p>Returns:</p> Type Description <p>damagebin : Table with the land-use class numbers (1st column) and the</p> <p>damage for that land-use class (2nd column).</p> <p>damagemap : Map displaying the damage per grid cell of the area.</p> Source code in <code>damagescanner\\raster.py</code> <pre><code>def RasterScanner(\n    exposure_file,\n    hazard_file,\n    curve_path,\n    maxdam_path,\n    lu_crs=28992,\n    haz_crs=4326,\n    hazard_col=\"FX\",\n    dtype=np.int32,\n    save=False,\n    **kwargs,\n):\n    \"\"\"\n    Raster-based implementation of a direct damage assessment.\n\n    Arguments:\n        *landuse_file* : GeoTiff with land-use information per grid cell. Make sure\n        the land-use categories correspond with the curves and maximum damages\n        (see below). Furthermore, the resolution and extend of the land-use map\n        has to be exactly the same as the inundation map.\n\n        *hazard_file* : GeoTiff or netCDF4 with hazard intensity per grid cell. Make sure\n        that the unit of the hazard map corresponds with the unit of the\n        first column of the curves file.\n\n        *curve_path* : File with the stage-damage curves of the different\n        land-use classes. Values should be given as ratios, i.e. between 0 and 1.\n        Can also be a pandas DataFrame or numpy Array.\n\n        *maxdam_path* : File with the maximum damages per land-use class\n        (in euro/m2). Can also be a pandas DataFrame or numpy Array.\n\n        *dtype*: Set the dtype to the requires precision. This will affect the output damage raster as well\n\n    Optional Arguments:\n        *save* : Set to True if you would like to save the output. Requires\n        several **kwargs**\n\n    kwargs:\n        *nan_value* : if nan_value is provided, will mask the inundation file.\n        This option can significantly fasten computations\n\n        *cell_size* : If both the landuse and hazard map are numpy arrays,\n        manually set the cell size.\n\n        *resolution* : If landuse is a numpy array, but the hazard map\n        is a netcdf, you need to specify the resolution of the landuse map.\n\n        *output_path* : Specify where files should be saved.\n\n        *scenario_name*: Give a unique name for the files that are going to be saved.\n\n        *in_millions*: Set to True if all values should be set in millions.\n\n        *crs*: Specify crs if you only read in two numpy array\n\n        *transform*: Specify transform if you only read in numpy arrays in order to save the result raster\n\n    Raises:\n        *ValueError* : on missing kwarg options\n\n    Returns:\n     *damagebin* : Table with the land-use class numbers (1st column) and the\n     damage for that land-use class (2nd column).\n\n     *damagemap* : Map displaying the damage per grid cell of the area.\n\n    \"\"\"\n    # load land-use map\n    if isinstance(exposure_file, PurePath):\n        with rasterio.open(exposure_file) as src:\n            landuse = src.read()[0, :, :]\n            transform = src.transform\n            resolution = src.res[0]\n            cellsize = src.res[0] * src.res[1]\n    else:\n        landuse = exposure_file.copy()\n\n    landuse_in = landuse.copy()\n\n    # Load hazard map\n    if isinstance(hazard_file, PurePath):\n        if hazard_file.parts[-1].endswith(\".tif\") | hazard_file.parts[-1].endswith(\n            \".tiff\"\n        ):\n            with rasterio.open(hazard_file) as src:\n                hazard = src.read()[0, :, :]\n                transform = src.transform\n\n        elif hazard_file.parts[-1].endswith(\".nc\"):\n            # Open the hazard netcdf file and store it in the hazard variable\n            hazard = xr.open_dataset(hazard_file)\n\n            # Open the landuse geotiff file and store it in the landuse variable\n            landuse = xr.open_dataset(exposure_file, engine=\"rasterio\")\n\n            # Match raster to vector\n            hazard, landuse = _match_raster_to_vector(\n                hazard, landuse, lu_crs, haz_crs, resolution, hazard_col\n            )\n\n    elif isinstance(hazard_file, xr.Dataset):\n        # Open the landuse geotiff file and store it in the landuse variable\n        landuse = xr.open_dataset(exposure_file, engine=\"rasterio\")\n\n        # Match raster to vector\n        hazard, landuse = _match_raster_to_vector(\n            hazard_file, landuse, lu_crs, haz_crs, resolution, hazard_col\n        )\n\n    else:\n        hazard = hazard_file.copy()\n\n    # check if land-use and hazard map have the same shape.\n    if landuse.shape != hazard.shape:\n        warnings.warn(\n            \"WARNING: landuse and hazard maps are not the same shape. Let's fix this first!\"\n        )\n\n        landuse, hazard, intersection = _match_rasters(exposure_file, hazard_file)\n\n        # create the right affine for saving the output\n        transform = Affine(\n            transform[0],\n            transform[1],\n            intersection[0],\n            transform[3],\n            transform[4],\n            intersection[1],\n        )\n\n    # set cellsize:\n    if isinstance(exposure_file, PurePath) | isinstance(hazard_file, PurePath):\n        cellsize = src.res[0] * src.res[1]\n    else:\n        try:\n            cellsize = kwargs[\"cellsize\"]\n        except KeyError:\n            raise ValueError(\"Required `cellsize` not given.\")\n\n    # Load curves\n    if isinstance(curve_path, pd.DataFrame):\n        curves = curve_path.values\n    elif isinstance(curve_path, np.ndarray):\n        curves = curve_path\n    elif curve_path.parts[-1].endswith(\".csv\"):\n        curves = pd.read_csv(curve_path).values\n\n    if ((curves &gt; 1).all()) or ((curves &lt; 0).all()):\n        raise ValueError(\"Stage-damage curve values must be between 0 and 1\")\n\n    # Load maximum damages\n    if isinstance(maxdam_path, pd.DataFrame):\n        maxdam = maxdam_path.values\n    elif isinstance(maxdam_path, np.ndarray):\n        maxdam = maxdam_path\n    elif maxdam_path.parts[-1].endswith(\".csv\"):\n        maxdam = pd.read_csv(maxdam_path).values\n\n    if maxdam.shape[0] != (curves.shape[1] - 1):\n        raise ValueError(\n            \"Dimensions between maximum damages and the number of depth-damage curve do not agree\"\n        )\n\n    # Speed up calculation by only considering feasible points\n    if kwargs.get(\"nan_value\"):\n        nan_value = kwargs.get(\"nan_value\")\n        hazard[hazard == nan_value] = 0\n\n    haz = hazard * (hazard &gt;= 0) + 0\n    haz[haz &gt;= curves[:, 0].max()] = curves[:, 0].max()\n    area = haz &gt; 0\n    haz_intensity = haz[haz &gt; 0]\n    landuse = landuse[haz &gt; 0]\n\n    # Calculate damage per land-use class for structures\n    numberofclasses = len(maxdam)\n    alldamage = np.zeros(landuse.shape[0])\n    damagebin = np.zeros(\n        (\n            numberofclasses,\n            2,\n        )\n    )\n    for i in range(0, numberofclasses):\n        n = maxdam[i, 0]\n        damagebin[i, 0] = n\n        wd = haz_intensity[landuse == n]\n        alpha = np.interp(wd, (curves[:, 0]), curves[:, i + 1])\n        damage = alpha * (maxdam[i, 1] * cellsize)\n        damagebin[i, 1] = sum(damage)\n        alldamage[landuse == n] = damage\n\n    # create the damagemap\n    damagemap = np.zeros((area.shape[0], area.shape[1]), dtype=dtype)\n    damagemap[area] = alldamage\n\n    # create pandas dataframe with output\n    damage_df = (\n        pd.DataFrame(damagebin.astype(dtype), columns=[\"landuse\", \"damages\"])\n        .groupby(\"landuse\")\n        .sum()\n    )\n\n    if save:\n        crs = kwargs.get(\"crs\", src.crs)\n        transform = kwargs.get(\"transform\", transform)\n\n        # requires adding output_path and scenario_name to function call\n        # If output path is not defined, will place file in current directory\n        output_path = _check_output_path(kwargs)\n        scenario_name = _check_scenario_name(kwargs)\n        path_prefix = PurePath(output_path, scenario_name)\n\n        damage_fn = \"{}_damages.csv\".format(path_prefix)\n        damage_df.to_csv(damage_fn)\n\n        dmap_fn = \"{}_damagemap.tif\".format(path_prefix)\n        rst_opts = {\n            \"driver\": \"GTiff\",\n            \"height\": damagemap.shape[0],\n            \"width\": damagemap.shape[1],\n            \"count\": 1,\n            \"dtype\": dtype,\n            \"crs\": crs,\n            \"transform\": transform,\n            \"compress\": \"LZW\",\n        }\n        with rasterio.open(dmap_fn, \"w\", **rst_opts) as dst:\n            dst.write(damagemap, 1)\n\n    if \"in_millions\" in kwargs:\n        damage_df = damage_df / 1e6\n\n    # return output\n    return damage_df, damagemap, landuse_in, hazard\n</code></pre>"},{"location":"get_started/","title":"Getting started","text":"<p>After installation, the tool works fairly straightforward. </p> <p>If you want to do a raster-based calculation, use the RasterScanner. If you want  to do a vector-based calculation, use the VectorScanner.</p> <p>Please find below examples using the example data stored on the GitHub.</p>"},{"location":"get_started/#a-raster-based-approach","title":"A raster-based approach","text":"<pre><code>import os\n\n# import the RasterScanner\nfrom damagescanner.core import RasterScanner\n\n# set paths to the data\ninun_map = os.path.join(data_path,'data','inundation','inundation_map.tif')\nlanduse_map = os.path.join(data_path,'data','landuse','landuse_map.tif')\ncurve_path = os.path.join(data_path,'data','curves','curves.csv')\nmaxdam_path = os.path.join(data_path,'data','curves','maxdam.csv')\n\n# run the RasterScanner and return a pandas DataFrame with loss per land-use class\nloss_df = RasterScanner(landuse_map,inun_map,curve_path,maxdam_path)[0]\n</code></pre>"},{"location":"get_started/#a-vector-based-approach","title":"A vector-based approach","text":"<pre><code># import necessary packages\nimport os\nimport numpy\nimport pandas\n\n# import the RasterScanner\nfrom damagescanner.core import VectorScanner\n\n# set paths to the data\ninun_map = os.path.join(data_path,'data','inundation','inundation_map.tif')\nlanduse_map = os.path.join(data_path,'data','landuse','landuse.shp')\n\n# Create maximum damage dictionary\nmaxdam = {\"grass\":5,\n    \"forest\":10,\n    \"orchard\":50,\n    \"residential\":200,\n    \"industrial\":300,\n    \"retail\":300,\n    \"farmland\":10,\n    \"cemetery\":15,\n    \"construction\":10,\n    \"meadow\":5,\n    \"farmyard\":5,\n    \"scrub\":5,\n    \"allotments\":10,\n    \"reservoir\":5,\n    \"static_caravan\":100,\n    \"commercial\":300}\n\n# Create some dummy curves that will match the land-use classes\ncurves = numpy.array(\n        [[0,0],\n        [50,0.2],\n        [100,0.4],\n        [150,0.6],\n        [200,0.8],\n        [250,1]])\n\ncurves = numpy.concatenate((curves,\n                            numpy.transpose(numpy.array([curves[:,1]]*(len(maxdam)-1)))),\n                           axis=1)\n\ncurves = pandas.DataFrame(curves)\ncurves.columns = ['depth']+list(maxdam.keys())\ncurves.set_index('depth',inplace=True)\n\n# run the VectorScanner and return the landuse map with damage values\nloss_df = VectorScanner(landuse,inun_map,curves,maxdam)\n</code></pre>"}]}
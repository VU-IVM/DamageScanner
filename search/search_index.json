{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started","text":""},{"location":"#damagescanner-direct-damage-assessments-for-natural-hazards","title":"DamageScanner: direct damage assessments for natural hazards","text":"<p>A python toolkit for direct damage assessments for natural hazards. Even though the method is initially developed for flood damage assessments, it can calculate damages for any hazard for which you just require a vulnerability curve (i.e. a one-dimensional relation). </p> <p>Please note: This package is still in development phase. In case of any problems, or if you have any suggestions for improvements, please raise an issue. </p>"},{"location":"#key-features","title":"\ud83d\udd11 Key Features","text":"<ul> <li>\u26a1 Modular design \u2014 Choose between raster-based or vector-based workflows</li> <li>\ud83d\udce6 Out-of-the-box methods \u2014 for exposure loading, raster-vector overlays, and damage estimation</li> <li>\ud83e\udde0 Damage functions \u2014 Apply your own vulnerability curves with flexible input formats</li> <li>\ud83d\uddfa\ufe0f Open geospatial stack \u2014 Built on GeoPandas, Rasterio, Shapely, and more</li> <li>\ud83e\uddea Easy API access \u2014 Use the Python interface directly or integrate into notebooks</li> </ul>"},{"location":"#background","title":"\ud83d\udcd6 Background","text":"<p>This package is (loosely) based on the original DamageScanner, which calculated potential flood damages based on inundation depth and land use using depth-damage curves in the Netherlands. The DamageScanner was originally developed for the 'Netherlands Later' project (Klijn et al., 2007). The original land-use classes were based on the Land-Use Scanner in order to evaluate the effect of future land-use change on flood damages. </p>"},{"location":"#quickstart","title":"\ud83d\ude80 Quickstart","text":"<ol> <li>Open the python environment in your command prompt or bash in which you want to install this package.</li> <li>Type <code>pip install damagescanner</code> and it should install itself into your python environment.</li> <li>Now you can import the package like any other package!</li> </ol>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for details.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#core-module","title":"Core Module","text":""},{"location":"api/#damagescanner.core.DamageScanner.exposure","title":"<code>exposure(disable_progress=False, **kwargs)</code>","text":"<p>Exposure data</p> Source code in <code>damagescanner\\core.py</code> <pre><code>def exposure(self, disable_progress=False, **kwargs):\n    \"\"\"Exposure data\"\"\"\n\n    if self.assessment_type == \"raster\":\n        return xr.open_rasterio(self.exposure_data)\n\n    elif self.assessment_type == \"vector\":\n        # specificy essential data input characteristics\n        if \"asset_type\" in kwargs:\n            self.asset_type = kwargs.get(\"asset_type\")\n        else:\n            self.asset_type = \"landuse\"\n\n        exposed_assets = VectorExposure(\n            hazard_file=self.hazard_data,\n            feature_file=self.feature_data,\n            asset_type=self.asset_type,\n            disable_progress=disable_progress,\n        )[0]\n\n        return exposed_assets\n</code></pre>"},{"location":"api/#damagescanner.core.DamageScanner.calculate","title":"<code>calculate(disable_progress=False, save_output=False, **kwargs)</code>","text":"<p>Damage assessment. Can be a specific hazard event, or a specific             single hazard footprint, or a list of events/footprints.</p> Source code in <code>damagescanner\\core.py</code> <pre><code>def calculate(self, disable_progress=False, save_output=False, **kwargs):\n    \"\"\"Damage assessment. Can be a specific hazard event, or a specific \\\n        single hazard footprint, or a list of events/footprints.\"\"\"\n\n    if not hasattr(self, \"assessment_type\"):\n        raise ImportError(\"Please prepare the input data first\")\n\n    if self.assessment_type == \"raster\":\n        return RasterScanner(\n            exposure_file=self.feature_data,\n            hazard_file=self.hazard_data,\n            curve_path=self.curves,\n            maxdam_path=self.maxdam,\n            save=save_output,\n        )\n\n    elif self.assessment_type == \"vector\":\n        # specificy essential data input characteristics\n        if \"asset_type\" in kwargs:\n            self.asset_type = kwargs.get(\"asset_type\")\n        else:\n            self.asset_type = None\n\n        return VectorScanner(\n            hazard_file=self.hazard_data,\n            feature_file=self.feature_data,\n            curve_path=self.curves,\n            maxdam_path=self.maxdam,\n            asset_type=self.asset_type,  #'landuse',\n            multi_curves=kwargs.get(\"multi_curves\", None),\n            sub_types=kwargs.get(\"subtypes\", None),\n            disable_progress=disable_progress,\n            save=save_output,\n        )\n</code></pre>"},{"location":"api/#damagescanner.core.DamageScanner.risk","title":"<code>risk(hazard_dict, **kwargs)</code>","text":"<p>Calculate the risk for a list of hazard events</p> Source code in <code>damagescanner\\core.py</code> <pre><code>def risk(self, hazard_dict, **kwargs):\n    \"\"\"\n    Calculate the risk for a list of hazard events\n    \"\"\"\n\n    RP_list = list(hazard_dict.keys())\n\n    risk = {}\n    for key, hazard_map in tqdm(\n        hazard_dict.items(), total=len(hazard_dict), desc=\"Risk Calculation\"\n    ):\n        if self.assessment_type == \"raster\":\n            risk[key] = DamageScanner(\n                hazard_map, self.feature_data, self.curves, self.maxdam\n            ).calculate(disable_progress=True)[0]\n        else:\n            if kwargs.get(\"asset_type\", None) is not None:\n                risk[key] = DamageScanner(\n                    hazard_map, self.feature_data, self.curves, self.maxdam\n                ).calculate(\n                    disable_progress=True, asset_type=kwargs.get(\"asset_type\")\n                )\n            elif kwargs.get(\"multi_curves\", None) is not None:\n                risk[key] = DamageScanner(\n                    hazard_map, self.feature_data, self.curves, self.maxdam\n                ).calculate(\n                    disable_progress=True, multi_curves=kwargs.get(\"multi_curves\")\n                )\n            else:\n                risk[key] = DamageScanner(\n                    hazard_map, self.feature_data, self.curves, self.maxdam\n                ).calculate(disable_progress=True)\n\n    # Collect the risk for each RP\n    df_risk = pd.concat(risk, axis=1)\n\n    if (len(df_risk) == 0) or (df_risk.isnull().all().all()):\n        return None\n\n    # Get the dataframe of the largest RP\n    largest_rp = df_risk.loc[:, pd.IndexSlice[RP_list[-1], :]]\n\n    if kwargs.get(\"multi_curves\", None) is None:\n        # only keep the damage values\n        df_risk = df_risk.loc[:, pd.IndexSlice[RP_list, \"damage\"]].fillna(0)\n\n        RPS = [1 / x for x in RP_list]\n\n        risk = pd.DataFrame(\n            df_risk.apply(\n                lambda x: integrate.simpson(y=x[RP_list][::-1], x=RPS[::-1]), axis=1\n            ),\n            columns=[\"tot_risk\"],\n        )\n\n        # save output when tot_risk returns negative values\n        if risk.tot_risk.min() &lt; 0:\n            df_risk.to_csv(\"df_risk.csv\")\n            risk.to_csv(\"risk.csv\")\n\n        # Save the risk to the largest RP\n        largest_rp.columns = largest_rp.columns.get_level_values(1)\n        largest_rp = largest_rp.drop(\"damage\", axis=1)\n        largest_rp.loc[:, \"risk\"] = risk.values\n\n        # return the risk in a concise dataframe\n        return largest_rp[[\"osm_id\", \"object_type\", \"geometry\", \"risk\"]]\n\n    else:\n        multi_curves = kwargs.get(\"multi_curves\")\n\n        # only keep the damage values\n        df_risk = df_risk.loc[\n            :, pd.IndexSlice[RP_list, multi_curves.keys()]\n        ].fillna(0)\n\n        RPS = [1 / x for x in RP_list]\n\n        # estimate risks\n        collect_risks = {}\n\n        for curve in multi_curves.keys():\n            subrisk = df_risk.loc[:, pd.IndexSlice[:, curve]]\n            collect_risks[curve] = subrisk.apply(\n                lambda x: integrate.simpson(y=x[RP_list][::-1], x=RPS[::-1]), axis=1\n            ).values\n\n            # save output when tot_risk returns negative values\n            if any(subrisk.min() &lt; 0):\n                df_risk.to_csv(\"df_risk.csv\")\n                subrisk.to_csv(\"risk.csv\")\n\n        all_risks = pd.DataFrame.from_dict(collect_risks)\n\n        largest_rp.columns = largest_rp.columns.get_level_values(1)\n        largest_rp = largest_rp.drop(multi_curves.keys(), axis=1)\n        largest_rp.loc[:, multi_curves.keys()] = all_risks.values\n\n        # return the risk in a concise dataframe\n        return largest_rp[\n            [\"osm_id\", \"object_type\", \"geometry\"] + list(multi_curves.keys())\n        ]\n</code></pre>"},{"location":"api/#vector-based-specific-functions","title":"Vector-based Specific Functions","text":""},{"location":"api/#damagescanner.vector.VectorExposure","title":"<code>VectorExposure(hazard_file, feature_file, asset_type='roads', object_col='object_type', disable_progress=False)</code>","text":"<p>Function to assess the exposure of objects.</p> <p>Parameters:</p> Name Type Description Default <code>hazard_file</code> <code>str</code> <p>Path to the hazard file.</p> required <code>exposure_file</code> <code>str</code> <p>Path to the exposure file.</p> required <p>Returns:</p> Type Description <p>gpd.GeoDataFrame: GeoDataFrame with the hazard and exposure information.</p> Source code in <code>damagescanner\\vector.py</code> <pre><code>def VectorExposure(hazard_file, feature_file, asset_type=\"roads\",object_col=\"object_type\", disable_progress=False):\n    \"\"\"\n    Function to assess the exposure of objects.\n\n    Args:\n        hazard_file (str): Path to the hazard file.\n        exposure_file (str): Path to the exposure file.\n\n    Returns:\n        gpd.GeoDataFrame: GeoDataFrame with the hazard and exposure information.\n    \"\"\"\n    # load exposure data\n    if isinstance(feature_file, PurePath):\n        # if exposure_file is a shapefile, geopackage or parquet file\n        if feature_file.suffix in [\".shp\", \".gpkg\", \"parquet\"]:\n            features = gpd.read_file(feature_file)\n\n        # if exposure_file is an osm.pbf file\n        elif feature_file.suffix == \".pbf\":\n            features = read_osm_data(feature_file, asset_type)\n            object_col = \"object_type\"\n        else:\n            raise ValueError(\n                \"exposure data should either be a shapefile, geopackage, parquet or osm.pbf file\"\n            )\n\n    elif isinstance(feature_file, gpd.GeoDataFrame) | isinstance(\n        feature_file, pd.DataFrame\n    ):\n        features = gpd.GeoDataFrame(feature_file.copy())\n\n    else:\n        raise ValueError(\n            \"exposure data should either be a shapefile, geopackage, parquet or osm.pbf file\"\n        )\n\n    if len(features) == 0:\n        hazard_crs = None\n        cell_area_m2 = None\n        return features, object_col, hazard_crs , cell_area_m2\n\n    # load hazard data\n    if isinstance(hazard_file, PurePath):\n        if hazard_file.suffix in [\".tif\", \".tiff\", \".nc\"]:\n            hazard = xr.open_dataset(hazard_file, engine=\"rasterio\")\n            hazard_crs = hazard.rio.crs\n\n            # check if crs is already in meters\n            if pyproj.CRS.from_epsg(hazard_crs.to_epsg()).axis_info[0].unit_name == \"metre\":\n                cell_area_m2 = (hazard.x[1].values - hazard.x[0].values) * (hazard.y[0].values - hazard.y[1].values)\n            else:\n                cell_area_m2 = _get_cell_area_m2(features,abs(hazard.rio.resolution()[0]))\n\n        elif hazard_file.suffix in [\".shp\", \".gpkg\", \".pbf\"]:\n            hazard = gpd.read_file(hazard_file)\n            hazard_crs = hazard.crs\n            cell_area_m2 = 1\n        else:\n            raise ValueError(\n                \"hazard data should either be a geotiff, netcdf, shapefile, geopackage or parquet file\"\n            )\n    elif isinstance(hazard_file, rasterio.io.DatasetReader):\n        hazard = hazard_file.copy()\n        hazard_crs = hazard.crs\n        cell_area_m2 = _get_cell_area_m2(features,abs(hazard.res[0]))\n    elif isinstance(hazard_file, (xr.Dataset, xr.DataArray)):   \n        hazard = hazard_file.copy()\n        hazard_crs = hazard.rio.crs\n\n        # check if crs is already in meters\n        if pyproj.CRS.from_epsg(hazard_crs.to_epsg()).axis_info[0].unit_name == \"metre\":\n            cell_area_m2 = (hazard.x[1].values - hazard.x[0].values) * (hazard.y[0].values - hazard.y[1].values)\n\n        # if not, extract it more cumbersome\n        else:\n            cell_area_m2 = _get_cell_area_m2(features,abs(hazard.rio.resolution()[0]))\n\n    elif isinstance(hazard, gpd.GeoDataFrame):\n        hazard = hazard_file.copy()\n        hazard_crs = hazard.crs\n        cell_area_m2 = 1\n    else:\n        raise ValueError(\n            f\"Hazard should be a raster or GeoDataFrame object, {type(hazard)} given\"\n        )\n\n    # Run exposure overlay\n    if isinstance(hazard, (rasterio.io.DatasetReader, xr.Dataset, xr.DataArray)):\n        features = _overlay_raster_vector(hazard, features, hazard_crs, disable_progress=disable_progress)\n    elif isinstance(hazard, (gpd.GeoDataFrame, pd.DataFrame)): \n        features = _overlay_vector_vector(hazard, features) ## NOT WORKING YET\n\n    return features, object_col, hazard_crs, cell_area_m2\n</code></pre>"},{"location":"api/#damagescanner.vector.VectorScanner","title":"<code>VectorScanner(hazard_file, feature_file, curve_path, maxdam_path, asset_type='roads', multi_curves=dict(), object_col='object_type', disable_progress=False, save=False, **kwargs)</code>","text":"<p>Vector based implementation of a direct damage assessment</p> <p>Parameters:</p> Name Type Description Default <code>*exposure_file*</code> <p>Shapefile, Pandas DataFrame or Geopandas GeoDataFrame</p> required <code>*hazard_file*</code> <p>GeoTiff with inundation depth per grid cell. Make sure</p> required <code>*curve_path*</code> <p>File with the stage-damage curves of the different</p> required <code>*maxdam_path*</code> <p>File with the maximum damages per land-use class</p> required <p>Optional Arguments:</p> <pre><code>*object_col* : Specify the column name of the unique object id's.\nDefault is set to **landuse**.\n\n*sub_types* : List of subtypes that should be included in the analysis.\n\n*save* : Set to True if you would like to save the output. Requires\nseveral **kwargs**\n</code></pre> kwargs <p>output_path : Specify where files should be saved.</p> <p>scenario_name: Give a unique name for the files that are going to be saved.</p> <p>Raises:</p> Type Description <code>*ValueError* </code> <p>on missing kwargs</p> <p>Returns:</p> Type Description <p>damagebin : Table with the land-use class names (1st column) and the</p> <p>damage for that land-use class (2nd column).</p> <p>TO DO: add the option to use vector data for the hazard as well.</p> Source code in <code>damagescanner\\vector.py</code> <pre><code>def VectorScanner(\n    hazard_file,\n    feature_file,\n    curve_path,\n    maxdam_path,\n    asset_type=\"roads\",\n    multi_curves=dict(),\n    object_col=\"object_type\",\n    disable_progress=False,\n    save=False,\n    **kwargs,\n):\n    \"\"\"\n    Vector based implementation of a direct damage assessment\n\n    Arguments:\n        *exposure_file* : Shapefile, Pandas DataFrame or Geopandas GeoDataFrame\n        with land-use information of the area.\n\n        *hazard_file* : GeoTiff with inundation depth per grid cell. Make sure\n        that the unit of the inundation map corresponds with the unit of the\n        first column of the curves file.\n\n        *curve_path* : File with the stage-damage curves of the different\n        land-use classes. Can also be a pandas DataFrame (but not a numpy Array).\n\n        *maxdam_path* : File with the maximum damages per land-use class\n        (in euro/m2). Can also be a pandas DataFrame (but not a numpy Array).\n\n    Optional Arguments:\n\n        *object_col* : Specify the column name of the unique object id's.\n        Default is set to **landuse**.\n\n        *sub_types* : List of subtypes that should be included in the analysis.\n\n        *save* : Set to True if you would like to save the output. Requires\n        several **kwargs**\n\n    kwargs:\n        *output_path* : Specify where files should be saved.\n\n        *scenario_name*: Give a unique name for the files that are going to be saved.\n\n    Raises:\n        *ValueError* : on missing kwargs\n\n    Returns:\n     *damagebin* : Table with the land-use class names (1st column) and the\n     damage for that land-use class (2nd column).\n\n    TO DO: add the option to use vector data for the hazard as well.\n\n    \"\"\"\n\n    # Load hazard and exposure data, and perform the overlay\n    features, object_col, hazard_crs, cell_area_m2 = VectorExposure(\n        hazard_file, feature_file, asset_type, object_col, disable_progress\n    )\n\n    if len(features) == 0:\n        return features\n\n    # Load curves\n    if isinstance(curve_path, pd.DataFrame):\n        curves = curve_path.copy()\n    elif isinstance(curve_path, np.ndarray):\n        raise ValueError(\n            \"For the vector-based approach we use a pandas DataFrame, not a Numpy Array\"\n        )\n    elif curve_path.parts[-1].endswith(\".csv\"):\n        curves = pd.read_csv(curve_path, index_col=[0])\n\n    # Load maximum damages\n    if isinstance(maxdam_path, PurePath) and maxdam_path.parts[-1].endswith(\".csv\"):\n        maxdam = pd.read_csv(maxdam_path)\n        maxdam = dict(zip(maxdam[\"object_type\"], maxdam[\"damage\"]))\n    elif isinstance(maxdam_path, pd.DataFrame):\n        maxdam = dict(zip(maxdam_path[\"object_type\"], maxdam_path[\"damage\"]))\n    elif isinstance(maxdam_path, np.ndarray):\n        maxdam = dict(zip(maxdam_path[:, 0], maxdam_path[:, 1]))\n    elif isinstance(maxdam_path, dict):\n        maxdam = maxdam_path\n\n    # remove features that are not part of this object type\n    if asset_type in DICT_CIS_VULNERABILITY_FLOOD.keys():\n        unique_objects_in_asset_type = list(DICT_CIS_VULNERABILITY_FLOOD[asset_type].keys())\n        features = features[features['object_type'].isin(unique_objects_in_asset_type)]\n\n    # connect maxdam to exposure\n    try:\n        features[\"maximum_damage\"] = features.apply(\n            lambda x: maxdam[x[\"object_type\"]], axis=1\n        )\n    except KeyError:\n        missing_object_types = [i for i in features.object_type.unique() if i not in maxdam.keys()]\n        raise KeyError(\n           f\"Not all object types in the exposure are included in the maximum damage file: {missing_object_types}\"\n        )\n\n    tqdm.pandas(desc=\"Calculating damage\",disable=disable_progress)\n\n    # Calculate damage\n    if not multi_curves:\n        features = _estimate_damage(features, curves, cell_area_m2)\n    else:\n        collect_sub_outcomes  = []\n        for curve_id in multi_curves:\n            curves = multi_curves[curve_id]\n            collect_sub_outcomes.append(_estimate_damage(features, curves, cell_area_m2)['damage'])\n\n        all_curve_damages = pd.concat(collect_sub_outcomes,axis=1)\n        all_curve_damages.columns = multi_curves.keys()\n\n        # add all curve damages to the features dataframe\n        features.loc[:,all_curve_damages.columns] = all_curve_damages\n\n        if 'damage' in features.columns:\n            features = features.drop(columns='damage')\n\n    # # Save output\n    # if save == True:\n    #     # requires adding output_path and scenario_name to function call\n    #     # If output path is not defined, will place file in current directory\n    #     output_path = _check_output_path(kwargs)\n    #     scenario_name = _check_scenario_name(kwargs)\n    #     path_prefix = PurePath(output_path, scenario_name)\n\n    #     damage_fn = f'{path_prefix}_damages.csv'\n    #     damaged_objects.to_csv(damage_fn)\n    #     return damaged_objects\n\n    # else:\n    #     return damaged_objects\n\n    return features\n</code></pre>"},{"location":"api/#raster-based-specific-functions","title":"Raster-based Specific Functions","text":""},{"location":"api/#damagescanner.raster.match_and_load_rasters","title":"<code>match_and_load_rasters(raster_in1, raster_in2)</code>","text":"<p>In case of a mismatch between two rasters, return only the intersecting parts.</p> <p>Code adapted from http://sciience.tumblr.com/post/101722591382/finding-the-georeferenced-intersection-between-two</p> <p>Parameters:</p> Name Type Description Default <code>*raster_in1*</code> <p>One of the two rasters to be clipped to the overlapping extent.</p> required <code>*raster_in2*</code> <p>One of the two rasters to be clipped to the overlapping extent.</p> required <p>Returns:</p> Type Description <p>array1 : Numpy Array of raster1</p> <p>array2 : Numpy Array of raster2</p> <p>intersection : Bounding box of overlapping part</p> Source code in <code>damagescanner\\raster.py</code> <pre><code>def match_and_load_rasters(raster_in1, raster_in2):\n    \"\"\"\n    In case of a mismatch between two rasters, return only the intersecting parts.\n\n    Code adapted from http://sciience.tumblr.com/post/101722591382/finding-the-georeferenced-intersection-between-two\n\n    Arguments:\n        *raster_in1* : One of the two rasters to be clipped to the overlapping extent.\n\n        *raster_in2* : One of the two rasters to be clipped to the overlapping extent.\n\n    Returns:\n        *array1* : Numpy Array of raster1\n\n        *array2* : Numpy Array of raster2\n\n        *intersection* : Bounding box of overlapping part\n\n    \"\"\"\n    with rasterio.open(raster_in1) as src1, rasterio.open(raster_in2) as src2:\n        if src1.crs != src2.crs:\n            raise ValueError(\"Different CRS: CRS must be the same.\")\n        if src1.res != src2.res:\n            raise ValueError(\"Different resolution: Cell sizes must be the same.\")\n\n        top_delta = round((src2.bounds.top - src1.bounds.top) / src1.transform.e)\n        bottom_delta = round(\n            (src2.bounds.bottom - src1.bounds.bottom) / src1.transform.e\n        )\n        left_delta = round((src2.bounds.left - src1.bounds.left) / src1.transform.a)\n        right_delta = round((src2.bounds.right - src1.bounds.right) / src1.transform.a)\n\n        data1 = src1.read(\n            1,\n            window=Window(\n                col_off=left_delta,\n                row_off=top_delta,\n                width=src1.width - left_delta + right_delta,\n                height=src1.height - top_delta + bottom_delta,\n            ),\n        )\n        data2 = src2.read(\n            1,\n            window=Window(\n                col_off=abs(min(left_delta, 0)),\n                row_off=abs(min(top_delta, 0)),\n                width=max(src1.width, src2.width) - abs(left_delta) - abs(right_delta),\n                height=max(src1.height, src2.height)\n                - abs(top_delta)\n                - abs(bottom_delta),\n            ),\n        )\n        transform = rasterio.Affine(\n            src1.transform.a,\n            src1.transform.b,\n            src1.transform.c + src1.transform.a * max(left_delta, 0),\n            src1.transform.d,\n            src1.transform.e,\n            src1.transform.f + src1.transform.e * max(top_delta, 0),\n        )\n\n    return data1, data2, transform\n</code></pre>"},{"location":"api/#damagescanner.raster.RasterScanner","title":"<code>RasterScanner(exposure_file, hazard_file, curve_path, maxdam_path, lu_crs=28992, haz_crs=4326, hazard_col='FX', dtype=np.int32, save=False, **kwargs)</code>","text":"<p>Raster-based implementation of a direct damage assessment.</p> <p>Parameters:</p> Name Type Description Default <code>*landuse_file*</code> <p>GeoTiff with land-use information per grid cell. Make sure</p> required <code>*hazard_file*</code> <p>GeoTiff or netCDF4 with hazard intensity per grid cell. Make sure</p> required <code>*curve_path*</code> <p>File with the stage-damage curves of the different</p> required <code>*maxdam_path*</code> <p>File with the maximum damages per land-use class</p> required <code>*dtype*</code> <p>Set the dtype to the requires precision. This will affect the output damage raster as well</p> required Optional Arguments <p>save : Set to True if you would like to save the output. Requires several kwargs</p> kwargs <p>nan_value : if nan_value is provided, will mask the inundation file. This option can significantly fasten computations</p> <p>cell_size : If both the landuse and hazard map are numpy arrays, manually set the cell size.</p> <p>resolution : If landuse is a numpy array, but the hazard map is a netcdf, you need to specify the resolution of the landuse map.</p> <p>output_path : Specify where files should be saved.</p> <p>scenario_name: Give a unique name for the files that are going to be saved.</p> <p>in_millions: Set to True if all values should be set in millions.</p> <p>crs: Specify crs if you only read in two numpy array</p> <p>transform: Specify transform if you only read in numpy arrays in order to save the result raster</p> <p>Raises:</p> Type Description <code>*ValueError* </code> <p>on missing kwarg options</p> <p>Returns:</p> Type Description <p>damagebin : Table with the land-use class numbers (1st column) and the</p> <p>damage for that land-use class (2nd column).</p> <p>damagemap : Map displaying the damage per grid cell of the area.</p> Source code in <code>damagescanner\\raster.py</code> <pre><code>def RasterScanner(\n    exposure_file,\n    hazard_file,\n    curve_path,\n    maxdam_path,\n    lu_crs=28992,\n    haz_crs=4326,\n    hazard_col=\"FX\",\n    dtype=np.int32,\n    save=False,\n    **kwargs,\n):\n    \"\"\"\n    Raster-based implementation of a direct damage assessment.\n\n    Arguments:\n        *landuse_file* : GeoTiff with land-use information per grid cell. Make sure\n        the land-use categories correspond with the curves and maximum damages\n        (see below). Furthermore, the resolution and extend of the land-use map\n        has to be exactly the same as the inundation map.\n\n        *hazard_file* : GeoTiff or netCDF4 with hazard intensity per grid cell. Make sure\n        that the unit of the hazard map corresponds with the unit of the\n        first column of the curves file.\n\n        *curve_path* : File with the stage-damage curves of the different\n        land-use classes. Values should be given as ratios, i.e. between 0 and 1.\n        Can also be a pandas DataFrame or numpy Array.\n\n        *maxdam_path* : File with the maximum damages per land-use class\n        (in euro/m2). Can also be a pandas DataFrame or numpy Array.\n\n        *dtype*: Set the dtype to the requires precision. This will affect the output damage raster as well\n\n    Optional Arguments:\n        *save* : Set to True if you would like to save the output. Requires\n        several **kwargs**\n\n    kwargs:\n        *nan_value* : if nan_value is provided, will mask the inundation file.\n        This option can significantly fasten computations\n\n        *cell_size* : If both the landuse and hazard map are numpy arrays,\n        manually set the cell size.\n\n        *resolution* : If landuse is a numpy array, but the hazard map\n        is a netcdf, you need to specify the resolution of the landuse map.\n\n        *output_path* : Specify where files should be saved.\n\n        *scenario_name*: Give a unique name for the files that are going to be saved.\n\n        *in_millions*: Set to True if all values should be set in millions.\n\n        *crs*: Specify crs if you only read in two numpy array\n\n        *transform*: Specify transform if you only read in numpy arrays in order to save the result raster\n\n    Raises:\n        *ValueError* : on missing kwarg options\n\n    Returns:\n     *damagebin* : Table with the land-use class numbers (1st column) and the\n     damage for that land-use class (2nd column).\n\n     *damagemap* : Map displaying the damage per grid cell of the area.\n\n    \"\"\"\n    # load land-use map\n    if isinstance(exposure_file, PurePath):\n        with rasterio.open(exposure_file) as src:\n            landuse = src.read()[0, :, :]\n            transform = src.transform\n            resolution = src.res[0]\n            cellsize = src.res[0] * src.res[1]\n    else:\n        landuse = exposure_file.copy()\n\n    landuse_in = landuse.copy()\n\n    # Load hazard map\n    if isinstance(hazard_file, PurePath):\n        if hazard_file.parts[-1].endswith(\".tif\") | hazard_file.parts[-1].endswith(\n            \".tiff\"\n        ):\n            with rasterio.open(hazard_file) as src:\n                hazard = src.read()[0, :, :]\n                transform = src.transform\n\n        elif hazard_file.parts[-1].endswith(\".nc\"):\n            # Open the hazard netcdf file and store it in the hazard variable\n            hazard = xr.open_dataset(hazard_file)\n\n            # Open the landuse geotiff file and store it in the landuse variable\n            landuse = xr.open_dataset(exposure_file, engine=\"rasterio\")\n\n            # Match raster to vector\n            hazard, landuse = _match_raster_to_vector(\n                hazard, landuse, lu_crs, haz_crs, resolution, hazard_col\n            )\n\n    elif isinstance(hazard_file, xr.Dataset):\n        # Open the landuse geotiff file and store it in the landuse variable\n        landuse = xr.open_dataset(exposure_file, engine=\"rasterio\")\n\n        # Match raster to vector\n        hazard, landuse = _match_raster_to_vector(\n            hazard_file, landuse, lu_crs, haz_crs, resolution, hazard_col\n        )\n\n    else:\n        hazard = hazard_file.copy()\n\n    # check if land-use and hazard map have the same shape.\n    if landuse.shape != hazard.shape:\n        warnings.warn(\n            \"WARNING: landuse and hazard maps are not the same shape. Let's fix this first!\"\n        )\n\n        landuse, hazard, intersection = _match_rasters(exposure_file, hazard_file)\n\n        # create the right affine for saving the output\n        transform = Affine(\n            transform[0],\n            transform[1],\n            intersection[0],\n            transform[3],\n            transform[4],\n            intersection[1],\n        )\n\n    # set cellsize:\n    if isinstance(exposure_file, PurePath) | isinstance(hazard_file, PurePath):\n        cellsize = src.res[0] * src.res[1]\n    else:\n        try:\n            cellsize = kwargs[\"cellsize\"]\n        except KeyError:\n            raise ValueError(\"Required `cellsize` not given.\")\n\n    # Load curves\n    if isinstance(curve_path, pd.DataFrame):\n        curves = curve_path.values\n    elif isinstance(curve_path, np.ndarray):\n        curves = curve_path\n    elif curve_path.parts[-1].endswith(\".csv\"):\n        curves = pd.read_csv(curve_path).values\n\n    if ((curves &gt; 1).all()) or ((curves &lt; 0).all()):\n        raise ValueError(\"Stage-damage curve values must be between 0 and 1\")\n\n    # Load maximum damages\n    if isinstance(maxdam_path, pd.DataFrame):\n        maxdam = maxdam_path.values\n    elif isinstance(maxdam_path, np.ndarray):\n        maxdam = maxdam_path\n    elif maxdam_path.parts[-1].endswith(\".csv\"):\n        maxdam = pd.read_csv(maxdam_path).values\n\n    if maxdam.shape[0] != (curves.shape[1] - 1):\n        raise ValueError(\n            \"Dimensions between maximum damages and the number of depth-damage curve do not agree\"\n        )\n\n    # Speed up calculation by only considering feasible points\n    if kwargs.get(\"nan_value\"):\n        nan_value = kwargs.get(\"nan_value\")\n        hazard[hazard == nan_value] = 0\n\n    haz = hazard * (hazard &gt;= 0) + 0\n    haz[haz &gt;= curves[:, 0].max()] = curves[:, 0].max()\n    area = haz &gt; 0\n    haz_intensity = haz[haz &gt; 0]\n    landuse = landuse[haz &gt; 0]\n\n    # Calculate damage per land-use class for structures\n    numberofclasses = len(maxdam)\n    alldamage = np.zeros(landuse.shape[0])\n    damagebin = np.zeros(\n        (\n            numberofclasses,\n            2,\n        )\n    )\n    for i in range(0, numberofclasses):\n        n = maxdam[i, 0]\n        damagebin[i, 0] = n\n        wd = haz_intensity[landuse == n]\n        alpha = np.interp(wd, (curves[:, 0]), curves[:, i + 1])\n        damage = alpha * (maxdam[i, 1] * cellsize)\n        damagebin[i, 1] = sum(damage)\n        alldamage[landuse == n] = damage\n\n    # create the damagemap\n    damagemap = np.zeros((area.shape[0], area.shape[1]), dtype=dtype)\n    damagemap[area] = alldamage\n\n    # create pandas dataframe with output\n    damage_df = (\n        pd.DataFrame(damagebin.astype(dtype), columns=[\"landuse\", \"damages\"])\n        .groupby(\"landuse\")\n        .sum()\n    )\n\n    if save:\n        crs = kwargs.get(\"crs\", src.crs)\n        transform = kwargs.get(\"transform\", transform)\n\n        # requires adding output_path and scenario_name to function call\n        # If output path is not defined, will place file in current directory\n        output_path = _check_output_path(kwargs)\n        scenario_name = _check_scenario_name(kwargs)\n        path_prefix = PurePath(output_path, scenario_name)\n\n        damage_fn = \"{}_damages.csv\".format(path_prefix)\n        damage_df.to_csv(damage_fn)\n\n        dmap_fn = \"{}_damagemap.tif\".format(path_prefix)\n        rst_opts = {\n            \"driver\": \"GTiff\",\n            \"height\": damagemap.shape[0],\n            \"width\": damagemap.shape[1],\n            \"count\": 1,\n            \"dtype\": dtype,\n            \"crs\": crs,\n            \"transform\": transform,\n            \"compress\": \"LZW\",\n        }\n        with rasterio.open(dmap_fn, \"w\", **rst_opts) as dst:\n            dst.write(damagemap, 1)\n\n    if \"in_millions\" in kwargs:\n        damage_df = damage_df / 1e6\n\n    # return output\n    return damage_df, damagemap, landuse_in, hazard\n</code></pre>"},{"location":"how-to/osm/","title":"Coupling with OpenStreetMap (OSM)","text":"<p>One of the powerful features of <code>DamageScanner</code> is the ability to work with OpenStreetMap (OSM) data as exposure input. This enables fast and global-scale exposure mapping, using freely available, crowdsourced infrastructure data.</p> <p>This page outlines how to prepare and use OSM data for damage assessment workflows, using <code>.osm.pbf</code> files directly.</p>"},{"location":"how-to/osm/#why-use-osm-data","title":"\ud83c\udf0d Why Use OSM Data?","text":"<ul> <li>Freely available, global coverage</li> <li>Includes many infrastructure types (roads, buildings, energy, healthcare, etc.)</li> <li>Constantly updated by the global community</li> <li>Works well with vector-based workflows in <code>DamageScanner</code></li> </ul> <p>\u26a0\ufe0f Note: OSM data quality and completeness can vary by location. Always validate your input.</p>"},{"location":"how-to/osm/#how-damagescanner-works-with-osm","title":"\u2699\ufe0f How DamageScanner Works with OSM","text":"<p>DamageScanner includes built-in support for working directly with <code>.osm.pbf</code> files. The tool provides utilities to:</p> <ul> <li>Download <code>.osm.pbf</code> files from Geofabrik</li> <li>Extract specific infrastructure classes</li> <li>Clean and preprocess the data into usable <code>GeoDataFrame</code> or <code>.gpkg</code></li> </ul> <p>These functions are implemented in: - <code>osm.py</code> - <code>download.py</code></p> <p>\u2705 This approach allows for highly automated and reproducible integration of OSM infrastructure.</p> <p>You can extract features like this:</p> <pre><code>from damagescanner.osm import read_osm_data\n\n# Read critical infrastructure data from an OSM .pbf file\nosm_path = \"data/netherlands-latest.osm.pbf\"\nfeatures = read_osm_data(osm_path, asset_type=\"road\")\n</code></pre> <p>The <code>asset_type</code> must be one of the predefined keys such as <code>road</code>, <code>rail</code>, <code>power</code>, <code>healthcare</code>, <code>education</code>, etc. The output is a cleaned GeoDataFrame with valid geometries and an <code>object_type</code> column.</p>"},{"location":"how-to/osm/#manual-tagging-optional","title":"\ud83e\uddfc Manual Tagging (Optional)","text":"<p>If you're preparing custom OSM files manually (e.g. from <code>.shp</code> or <code>.gpkg</code>):</p> <pre><code># Reproject and tag manually loaded GeoDataFrame\ngdf = gdf.to_crs(\"EPSG:32633\")\ngdf = gdf[gdf.geom_type.isin([\"LineString\", \"MultiLineString\"])]\ngdf[\"object_type\"] = \"road\"\n</code></pre> <p>\u26a0\ufe0f The required column name is always <code>object_type</code> \u2014 this is how DamageScanner matches features with vulnerability curves and max damage values.</p> <p>Save to file if needed:</p> <pre><code>gdf.to_file(\"data/cleaned_osm_roads.gpkg\", driver=\"GPKG\")\n</code></pre>"},{"location":"how-to/osm/#example-usage-with-damagescanner","title":"\ud83d\udca5 Example Usage with DamageScanner","text":"<pre><code>from damagescanner import DamageScanner\n\nhazard = \"data/flood_depth_100yr.tif\"\nosm_exposure = \"data/cleaned_osm_roads.gpkg\"\ncurves = \"data/vulnerability_curves.csv\"\nmaxdam = \"data/maxdam.csv\"\n\nscanner = DamageScanner(hazard, osm_exposure, curves, maxdam)\ndamage = scanner.calculate()\n</code></pre> <p>This calculates direct damages using cleaned vector infrastructure data from OSM.</p>"},{"location":"how-to/osm/#tips-for-reproducibility","title":"\ud83d\udd01 Tips for Reproducibility","text":"<ul> <li>Document the OSM extract date and source (e.g. Geofabrik region)</li> <li>Use consistent object naming (e.g. <code>road</code>, <code>bridge</code>, <code>hospital</code>) to match your vulnerability inputs</li> <li>Save your processed data in <code>.gpkg</code> or <code>.shp</code> format for reuse</li> </ul>"},{"location":"how-to/osm/#see-also","title":"\ud83d\udcda See Also","text":"<ul> <li>Overview</li> <li>Raster-based approach</li> <li>Vector-based approach</li> <li>GlobalInfraRisk OSM Guide</li> </ul>"},{"location":"how-to/overview/","title":"Overview","text":"<p><code>DamageScanner()</code> is a Python toolkit for direct damage assessments of natural hazards. While originally designed for flood risk analysis, it can be used for any hazard where vulnerability can be expressed as a one-dimensional curve (e.g., flood depth, wind speed, ground shaking).</p> <p>The tool is optimized for both raster-based hazards and vector-based assets (e.g., roads, power plants, buildings). This page walks you through how it works, and what is required for running a successful analysis.</p> <p>\ud83d\udcda For a very extensive overview of real-world examples, please refer to the GlobalInfraRisk documentation.</p>"},{"location":"how-to/overview/#core-workflow","title":"\ud83e\udde0 Core Workflow","text":"<p>The DamageScanner logic consists of three key steps:</p> <ol> <li>Exposure Analysis \u2014 identifies what assets intersect the hazard.</li> <li>Damage Calculation \u2014 estimates damage using vulnerability curves.</li> <li>Risk Assessment \u2014 aggregates damage across hazard return periods.</li> </ol>"},{"location":"how-to/overview/#inputs-required","title":"\ud83d\udd27 Inputs Required","text":"<p>The <code>DamageScanner</code> class requires four key inputs:</p>"},{"location":"how-to/overview/#1-hazard-data","title":"1. Hazard Data","text":"<ul> <li>Raster (GeoTIFF, NetCDF) or path to raster files</li> <li>Represents hazard intensity (e.g., flood depth, wind speed)</li> </ul>"},{"location":"how-to/overview/#2-exposure-data-aka-feature_data","title":"2. Exposure Data (aka <code>feature_data</code>)","text":"<ul> <li>Vector formats: <code>.shp</code>, <code>.gpkg</code>, <code>.pbf</code>, <code>.geoparquet</code>, or GeoDataFrames</li> <li>Raster exposure layers (<code>.tif</code>, <code>.nc</code>) also supported</li> <li>Automatically detects type from file extension</li> </ul>"},{"location":"how-to/overview/#3-vulnerability-curves","title":"3. Vulnerability Curves","text":"<ul> <li>CSV or <code>pandas.DataFrame</code></li> <li>Relates hazard intensity to damage (as fraction of max damage)</li> </ul> <p>\u26a0\ufe0f Important: The unit of the first column/index must match the unit of the hazard layer (e.g., meters for flood depth).</p>"},{"location":"how-to/overview/#4-maximum-damage-values","title":"4. Maximum Damage Values","text":"<ul> <li>Specifies the max value per asset type (e.g., \u20ac/m\u00b2 or \u20ac/asset)</li> <li>Provided as <code>dict</code>, CSV, or DataFrame</li> </ul>"},{"location":"how-to/overview/#example-running-damagescanner","title":"\ud83e\uddea Example: Running DamageScanner","text":"<pre><code>from damagescanner import DamageScanner\nimport pandas as pd\n\n# Paths to input files\nhazard = \"path/to/hazard_data.tif\"\nfeature_data = \"path/to/exposure_data.shp\"\ncurves = \"path/to/vulnerability_curves.csv\"\nmaxdam = \"path/to/maxdam.csv\"\n\n# Initialize\nscanner = DamageScanner(hazard, feature_data, curves, maxdam)\n</code></pre>"},{"location":"how-to/overview/#step-by-step-usage","title":"\ud83d\udd0d Step-by-Step Usage","text":""},{"location":"how-to/overview/#1-exposure","title":"1. <code>exposure()</code>","text":"<p>Identify which features overlap with the hazard.</p> <pre><code># Curves and maxdam must be empty DataFrames for exposure-only\nscanner = DamageScanner(hazard, feature_data, pd.DataFrame(), pd.DataFrame())\nexposed = scanner.exposure()\n</code></pre> <ul> <li>Works with both vector and raster feature data</li> <li>Results in a GeoDataFrame with assets intersecting the hazard</li> </ul>"},{"location":"how-to/overview/#2-calculate","title":"2. <code>calculate()</code>","text":"<p>Applies vulnerability curves to estimate damage.</p> <pre><code>results = scanner.calculate()\nprint(results.head())\n</code></pre> <ul> <li>Requires valid curves and <code>maxdam</code></li> <li>Damage is computed per asset, based on overlap and intensity</li> </ul>"},{"location":"how-to/overview/#3-risk","title":"3. <code>risk()</code>","text":"<p>Calculates risk over multiple return periods.</p> <pre><code>hazard_dict = {\n    10: \"hazard_10.tif\",\n    50: \"hazard_50.tif\",\n    100: \"hazard_100.tif\"\n}\n\nrisk_results = scanner.risk(hazard_dict)\n</code></pre> <ul> <li>Computes Expected Annual Damages (EAD) using return periods</li> <li>Supports asset-specific curves and max damages</li> </ul>"},{"location":"how-to/overview/#tips-for-working-with-geometry","title":"\ud83d\uddc2\ufe0f Tips for Working with Geometry","text":"<p>\u26a0\ufe0f Important: Make sure each asset type uses one geometry type (Point or Polygon). Options:</p> <ol> <li>Convert all assets to the same geometry</li> <li>Split the damage calc by geometry type</li> <li>Use custom object names like <code>substation_point</code> vs <code>substation_polygon</code></li> </ol>"},{"location":"how-to/overview/#next-steps","title":"\ud83d\udcda Next Steps","text":"<ul> <li>\ud83d\udce6 Raster-based approach</li> <li>\ud83d\udce6 Vector-based approach</li> <li>\ud83e\udded Coupling with OSM</li> </ul>"},{"location":"how-to/raster/","title":"Raster-based Approach","text":"<p>This page explains how to use <code>DamageScanner</code> with raster-based exposure and hazard data. This approach is especially useful when working with gridded exposure datasets, such as population grids, land use rasters, or economic value rasters.</p>"},{"location":"how-to/raster/#when-to-use-raster-based-workflows","title":"\ud83e\udde0 When to Use Raster-Based Workflows","text":"Scenario Raster-Based Vector-Based Gridded exposure data (e.g. land cover) \u2705 \u274c Building footprints or linear infrastructure \u274c \u2705 Country- or global-scale risk analysis \u2705 \u2705 Exposure not tied to individual assets \u2705 \u274c"},{"location":"how-to/raster/#required-inputs","title":"\ud83d\udd27 Required Inputs","text":"<p>You still need the same four key inputs as explained in the Overview:</p> <ol> <li>Hazard raster (e.g. flood depth, wind speed)</li> <li>Exposure raster (e.g. land use, population density)</li> <li>Vulnerability curves (CSV or DataFrame)</li> <li>Maximum damage values (CSV, dict, or DataFrame)</li> </ol> <p>\u26a0\ufe0f Ensure both hazard and exposure rasters are in the same CRS and aligned spatially (same resolution and extent) for optimal performance.</p>"},{"location":"how-to/raster/#minimal-working-example","title":"\ud83e\uddea Minimal Working Example","text":"<pre><code>from damagescanner import DamageScanner\n\nhazard = \"data/hazard_flood_depth.tif\"\nfeature_data = \"data/exposure_population_density.tif\"\ncurves = \"data/vulnerability_curves.csv\"\nmaxdam = \"data/maxdam.csv\"\n\nscanner = DamageScanner(hazard, feature_data, curves, maxdam)\ndamage = scanner.calculate()\n</code></pre> <p>This returns a <code>GeoDataFrame</code> where each grid cell contains an estimated direct damage value.</p>"},{"location":"how-to/raster/#notes-on-raster-behavior","title":"\ud83d\udcca Notes on Raster Behavior","text":"<ul> <li>Exposure values are interpreted as damageable units per cell (e.g., people, \u20ac value, or m\u00b2)</li> <li>Output damage is computed as:</li> </ul> <p>\\   <code>exposure * damage_fraction * max_damage</code></p> <ul> <li>The damage fraction is determined from the vulnerability curve, based on the hazard intensity in the same raster cell.</li> </ul>"},{"location":"how-to/raster/#common-pitfalls","title":"\ud83e\uddfc Common Pitfalls","text":"<p>\u26a0\ufe0f Misaligned Rasters \u2014 Make sure both rasters have the same extent, resolution, and CRS. You can use <code>rasterio.warp</code> or <code>gdalwarp</code> to resample.</p> <p>\u26a0\ufe0f Missing Data \u2014 NoData values can propagate through your analysis. Clean them or mask them before calculation.</p> <p>\u26a0\ufe0f Unit mismatch \u2014 Hazard units and curve x-axis must match exactly (e.g., meters, m/s).</p>"},{"location":"how-to/raster/#see-also","title":"\ud83d\udcda See Also","text":"<ul> <li>Overview</li> <li>Vector-based approach</li> <li>Coupling with OSM</li> </ul>"},{"location":"how-to/vector/","title":"Vector-based Approach","text":"<p>This page explains how to use <code>DamageScanner</code> with vector-based exposure data (e.g. shapefiles, GeoPackages, or OSM data). This approach is ideal for object-level damage estimation, such as buildings, roads, power plants, and other individual infrastructure assets.</p>"},{"location":"how-to/vector/#when-to-use-vector-based-workflows","title":"\ud83e\udde0 When to Use Vector-Based Workflows","text":"Scenario Raster-Based Vector-Based Infrastructure objects (e.g. bridges, roads) \u274c \u2705 OpenStreetMap data \u274c \u2705 Detailed local studies \u274c \u2705 Exposure linked to specific geometries \u274c \u2705"},{"location":"how-to/vector/#required-inputs","title":"\ud83d\udd27 Required Inputs","text":"<p>As described in the Overview, you need:</p> <ol> <li>Hazard raster (e.g. flood depth, wind speed)</li> <li>Exposure vector (e.g. buildings, roads \u2014 as <code>.shp</code>, <code>.gpkg</code>, <code>.pbf</code>, or <code>GeoDataFrame</code>)</li> <li>Vulnerability curves (CSV or DataFrame)</li> <li>Maximum damage values (CSV, dict, or DataFrame)</li> </ol> <p>\u26a0\ufe0f Your exposure data must include a column specifying asset type, matching the keys used in the vulnerability curves and max damage data.</p>"},{"location":"how-to/vector/#minimal-working-example","title":"\ud83e\uddea Minimal Working Example","text":"<pre><code>from damagescanner import DamageScanner\n\nhazard = \"data/hazard_flood_depth.tif\"\nfeature_data = \"data/infrastructure_osm.gpkg\"\ncurves = \"data/vulnerability_curves.csv\"\nmaxdam = \"data/maxdam.csv\"\n\nscanner = DamageScanner(hazard, feature_data, curves, maxdam)\ndamage = scanner.calculate()\n</code></pre> <p>The result is a <code>GeoDataFrame</code> of features with estimated direct damage values per asset.</p>"},{"location":"how-to/vector/#key-behavior","title":"\ud83d\udd0d Key Behavior","text":"<ul> <li>The exposure file must contain geometry columns (Point, LineString, or Polygon)</li> <li><code>DamageScanner</code> overlays each geometry with the hazard raster</li> <li>It then samples the hazard value and looks up the damage fraction from the corresponding vulnerability curve</li> <li>The damage is calculated as:</li> </ul> <p>\\   <code>exposure_area * damage_fraction * max_damage</code></p>"},{"location":"how-to/vector/#geometry-handling-tips","title":"\u26a0\ufe0f Geometry Handling Tips","text":"<p>\u26a0\ufe0f Mixed Geometry Types \u2014 Avoid mixing Points and Polygons for the same asset type.</p> <p>\u26a0\ufe0f CRS Alignment \u2014 Both hazard and vector data must be in the same coordinate reference system.</p> <p>\u26a0\ufe0f Object Column \u2014 You must define a column that links each object to a vulnerability curve and max damage.</p>"},{"location":"how-to/vector/#see-also","title":"\ud83d\udcda See Also","text":"<ul> <li>Overview</li> <li>Raster-based approach</li> <li>Coupling with OSM</li> </ul>"}]}